{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "40efb7d3-c85e-4ff0-b302-1303f7ea5b9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "src_path = \"../src\"\n",
    "sys.path.insert(0, src_path)\n",
    "\n",
    "hf_token = os.environ[\"HUGGINGFACE_TOKEN\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0e8f983-fcf6-47c7-a94e-2c70baba1591",
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import load_data\n",
    "from client import Client\n",
    "from tester import Tester"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fae755e2-1563-4b20-8240-8a8df17c250e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"../data/conversations_v1.pickle\", \"rb\") as conversation_file:\n",
    "    conversations = pickle.load(conversation_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6c3818fc-7136-406d-bb65-4de139290ff2",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [load_data(f\"../data/processed/train{i}.json\") for i in range(1, 4)]\n",
    "entries = data[0] | data[1]\n",
    "c = Client(\n",
    "    \"mistralai/Mistral-Nemo-Instruct-2407\",\n",
    "    token=hf_token,\n",
    ")\n",
    "t = Tester(c, entries)\n",
    "indices = sorted(list(entries.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7c43cac-d9b4-4d32-80c1-ef57e17bd546",
   "metadata": {},
   "outputs": [],
   "source": [
    "t.conversations = conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52d3007b-1130-441c-99c6-d1959e0474f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "computed_indices = indices[:396]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "813df6e0-fad7-4862-9e1d-16a078f0abd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy(score=743, total=1449, accuracy=0.5127674258109041)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.answer_accuracy(computed_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e74f33fc-1411-412b-a457-fefdd44826ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add': Accuracy(score=80, total=140, accuracy=0.5714285714285714),\n",
       " 'subtract': Accuracy(score=130, total=306, accuracy=0.42483660130718953),\n",
       " 'multiply': Accuracy(score=22, total=62, accuracy=0.3548387096774194),\n",
       " 'divide': Accuracy(score=171, total=413, accuracy=0.41404358353510895),\n",
       " 'exp': Accuracy(score=0, total=0, accuracy=0),\n",
       " 'greater': Accuracy(score=2, total=3, accuracy=0.6666666666666666)}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.answer_accuracy_by_operation(computed_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ea328c8d-4166-4caa-88ff-ecb0a4253273",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Accuracy(score=236, total=396, accuracy=0.5959595959595959),\n",
       " Accuracy(score=217, total=394, accuracy=0.550761421319797),\n",
       " Accuracy(score=134, total=298, accuracy=0.44966442953020136),\n",
       " Accuracy(score=85, total=208, accuracy=0.40865384615384615),\n",
       " Accuracy(score=45, total=98, accuracy=0.45918367346938777),\n",
       " Accuracy(score=20, total=41, accuracy=0.4878048780487805),\n",
       " Accuracy(score=5, total=11, accuracy=0.45454545454545453),\n",
       " Accuracy(score=1, total=3, accuracy=0.3333333333333333)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.answer_accuracy_by_question_number(computed_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3ed0e5fd-b562-4aff-baa6-9cc13a16841a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'retrieval': Accuracy(score=338, total=525, accuracy=0.6438095238095238),\n",
       " 'program': Accuracy(score=405, total=924, accuracy=0.4383116883116883)}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.answer_accuracy_by_question_type(computed_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f2d5d24f-8ab6-4848-8b54-7312698b4eb9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Accuracy(score=547, total=924, accuracy=0.591991341991342)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.program_accuracy(computed_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9b84770b-f84a-4b54-b62c-6f9c8a6e288e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'add': Accuracy(score=101, total=140, accuracy=0.7214285714285714),\n",
       " 'subtract': Accuracy(score=150, total=306, accuracy=0.49019607843137253),\n",
       " 'multiply': Accuracy(score=27, total=62, accuracy=0.43548387096774194),\n",
       " 'divide': Accuracy(score=268, total=413, accuracy=0.648910411622276),\n",
       " 'exp': Accuracy(score=0, total=0, accuracy=0),\n",
       " 'greater': Accuracy(score=1, total=3, accuracy=0.3333333333333333)}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.program_accuracy_by_operation(computed_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed472e92-c490-4e5f-885f-765f5ecbeef6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Accuracy(score=102, total=211, accuracy=0.4834123222748815),\n",
       " Accuracy(score=82, total=155, accuracy=0.5290322580645161),\n",
       " Accuracy(score=182, total=279, accuracy=0.6523297491039427),\n",
       " Accuracy(score=90, total=149, accuracy=0.6040268456375839),\n",
       " Accuracy(score=60, total=80, accuracy=0.75),\n",
       " Accuracy(score=24, total=38, accuracy=0.631578947368421),\n",
       " Accuracy(score=5, total=9, accuracy=0.5555555555555556),\n",
       " Accuracy(score=2, total=3, accuracy=0.6666666666666666)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.program_accuracy_by_question_number(computed_indices)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ConvFinQA",
   "language": "python",
   "name": "convfinqa"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
